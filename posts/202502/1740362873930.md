---
title: Java-源码-JDK1.8-HashMap
tags:
  - Java
  - HashMap
date: '2025-01-24 10:07:53'
image: /true-duck.png
isNewest: true
isFeatured: false
isDeleted: false
---
## 前言

本文针对 JDK 1.8 的 HashMap 进行总结。

建议没读过源码的可以认真过一下，看过源码可以直接跳总结。

## 属性

- 初始化属性

```java
public class HashMap<K,V> extends AbstractMap<K,V>
    implements Map<K,V>, Cloneable, Serializable {
    //序列号，序列化的时候使用。
    private static final long serialVersionUID = 362498820763181265L;
    /**默认容量，1向左移位4个，00000001变成00010000，也就是2的4次方为16，使用移位是因为移位是计算机基础运算，效率比加减乘除快。**/
    static final int DEFAULT_INITIAL_CAPACITY = 1 << 4;
    //最大容量，2的30次方。
    static final int MAXIMUM_CAPACITY = 1 << 30;
    //加载因子，用于扩容使用。
    static final float DEFAULT_LOAD_FACTOR = 0.75f;
    //当某个桶节点数量达到8时，会转换为红黑树。
    static final int TREEIFY_THRESHOLD = 8;
    //当某个桶节点数量小于6时，会转换为链表，前提是它当前是红黑树结构。
    static final int UNTREEIFY_THRESHOLD = 6;
    //当整个hashMap中元素数量达到64时，也会进行转为红黑树结构。
    static final int MIN_TREEIFY_CAPACITY = 64;
    //存储元素的数组，transient关键字表示该属性不能被序列化
    transient Node<K,V>[] table;
    //将数据转换成set的另一种存储形式，这个变量主要用于迭代功能。
    transient Set<Map.Entry<K,V>> entrySet;
    //元素数量
    transient int size;
    //统计该map修改的次数 支持快速失败y
    transient int modCount;
    //临界值，也就是元素数量达到临界值时，会进行扩容。
    int threshold;
    //也是加载因子，只不过这个是变量。
    final float loadFactor;  
}
```

- 初始化内部类

两个节点，针对链表以及红黑树而设计。

```java
static final class TreeNode<K,V> extends LinkedHashMap.Entry<K,V> {
        TreeNode<K,V> parent;  
        TreeNode<K,V> left;
        TreeNode<K,V> right;
        TreeNode<K,V> prev;    
        boolean red;
        TreeNode(int hash, K key, V val, Node<K,V> next) {
            super(hash, key, val, next);
        }
}
static class Node<K,V> implements Map.Entry<K,V> {
        final int hash;
        final K key;
        V value;
        Node<K,V> next;
 
        Node(int hash, K key, V value, Node<K,V> next) {
            this.hash = hash;
            this.key = key;
            this.value = value;
            this.next = next;
        }
}
```

## 构造方法

```java
	// 1.使用默认加载因子    
	public HashMap() {
        this.loadFactor = DEFAULT_LOAD_FACTOR; 
    }
 	
 	// 2.设置容量
    public HashMap(int initialCapacity) {
        this(initialCapacity, DEFAULT_LOAD_FACTOR);
    }
 
    // 3.设置初始容量和加载因子
    public HashMap(int initialCapacity, float loadFactor) {
        if (initialCapacity < 0)
            throw new IllegalArgumentException("Illegal initial capacity: " + initialCapacity);
        if (initialCapacity > MAXIMUM_CAPACITY)
            initialCapacity = MAXIMUM_CAPACITY;
        if (loadFactor <= 0 || Float.isNaN(loadFactor))
            throw new IllegalArgumentException("Illegal load factor: " + loadFactor);
        this.loadFactor = loadFactor;
        this.threshold = tableSizeFor(initialCapacity);
    }

    // 4. 传入一个map， putMapEntries是把map转化成hashmap
    public HashMap(Map<? extends K, ? extends V> m) {
        this.loadFactor = DEFAULT_LOAD_FACTOR;
        putMapEntries(m, false);
    }
 
 
    final void putMapEntries(Map<? extends K, ? extends V> m, boolean evict) {
        //获取该map的实际长度
        int s = m.size();
        if (s > 0) {
            //判断table是否初始化，如果没有初始化
            if (table == null) { // pre-size
                /**求出需要的容量，因为实际使用的长度=容量*0.75得来的，+1是因为小数相除，基本都不会是整数，容量大小不能为小数的，后面转换为int，多余的小数就要被丢掉，所以+1，例如，map实际长度22，22/0.75=29.3,所需要的容量肯定为30，有人会问如果刚刚好除得整数呢，除得整数的话，容量大小多1也没什么影响**/
                float ft = ((float)s / loadFactor) + 1.0F;
                //判断该容量大小是否超出上限。
                int t = ((ft < (float)MAXIMUM_CAPACITY) ?
                         (int)ft : MAXIMUM_CAPACITY);
                /**对临界值进行初始化，tableSizeFor(t)这个方法会返回大于t值的，且离其最近的2次幂，例如t为29，则返回的值是32**/
                if (t > threshold)
                    threshold = tableSizeFor(t);
            }
            //如果table已经初始化，则进行扩容操作，resize()就是扩容。
            else if (s > threshold)
                resize();
            //遍历，把map中的数据转到hashMap中。
            for (Map.Entry<? extends K, ? extends V> e : m.entrySet()) {
                K key = e.getKey();
                V value = e.getValue();
                putVal(hash(key), key, value, false, evict);
            }
        }
    }
```

## put

- hash

```java
static final int hash(Object key) {
    int h;
    /**先获取到key的hashCode，然后进行移位再进行异或运算，为什么这么复杂，不用想肯定是为了减少hash冲突**/
    return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);
}
```

- resize

```java
final Node<K,V>[] resize() {
    //把没插入之前的哈希数组oldTal
    Node<K,V>[] oldTab = table;
    //old的长度
    int oldCap = (oldTab == null) ? 0 : oldTab.length;
    //old的临界值
    int oldThr = threshold;
    //初始化new的长度和临界值
    int newCap, newThr = 0;
    //oldCap > 0也就是说不是首次初始化，因为hashMap用的是懒加载
    if (oldCap > 0) {
        //大于最大值
        if (oldCap >= MAXIMUM_CAPACITY) {
            //临界值为整数的最大值
            threshold = Integer.MAX_VALUE;
            return oldTab;
        }
        //标记##，其它情况，扩容两倍，并且扩容后的长度要小于最大值，old长度也要大于16
        else if ((newCap = oldCap << 1) < MAXIMUM_CAPACITY &&
                 oldCap >= DEFAULT_INITIAL_CAPACITY)
            //临界值也扩容为old的临界值2倍
            newThr = oldThr << 1; 
    }
    /**如果oldCap<0，但是已经初始化了，像把元素删除完之后的情况，那么它的临界值肯定还存在，        
       如果是首次初始化，它的临界值则为0
    **/
    else if (oldThr > 0) 
        newCap = oldThr;
    //首次初始化，给与默认的值
    else {               
        newCap = DEFAULT_INITIAL_CAPACITY;
        //临界值等于容量*加载因子
        newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY);
    }
    //此处的if为上面标记##的补充，也就是初始化时容量小于默认值16的，此时newThr没有赋值
    if (newThr == 0) {
        //new的临界值
        float ft = (float)newCap * loadFactor;
        //判断是否new容量是否大于最大值，临界值是否大于最大值
        newThr = (newCap < MAXIMUM_CAPACITY && ft < (float)MAXIMUM_CAPACITY ?
                  (int)ft : Integer.MAX_VALUE);
    }
    //把上面各种情况分析出的临界值，在此处真正进行改变，也就是容量和临界值都改变了。
    threshold = newThr;
    //表示忽略该警告
    @SuppressWarnings({"rawtypes","unchecked"})
        //初始化
        Node<K,V>[] newTab = (Node<K,V>[])new Node[newCap];
    //赋予当前的table
    table = newTab;
    //此处自然是把old中的元素，遍历到new中
    if (oldTab != null) {
        for (int j = 0; j < oldCap; ++j) {
            //临时变量
            Node<K,V> e;
            //当前哈希桶的位置值不为null，也就是数组下标处有值，因为有值表示可能会发生冲突
            if ((e = oldTab[j]) != null) {
                //把已经赋值之后的变量置位null，当然是为了好回收，释放内存
                oldTab[j] = null;
                //如果下标处的节点没有下一个元素
                if (e.next == null)
                    //把该变量的值存入newCap中，e.hash & (newCap - 1)并不等于j
                    newTab[e.hash & (newCap - 1)] = e;
                //该节点为红黑树结构，也就是存在哈希冲突，该哈希桶中有多个元素
                else if (e instanceof TreeNode)
                    //把此树进行转移到newCap中
                    ((TreeNode<K,V>)e).split(this, newTab, j, oldCap);
                else { /**此处表示为链表结构，同样把链表转移到newCap中，就是把链表遍历后，把值转过去，在置位null**/
                    Node<K,V> loHead = null, loTail = null;
                    Node<K,V> hiHead = null, hiTail = null;
                    Node<K,V> next;
                    do {
                        next = e.next;
                        if ((e.hash & oldCap) == 0) {
                            if (loTail == null)
                                loHead = e;
                            else
                                loTail.next = e;
                            loTail = e;
                        }
                        else {
                            if (hiTail == null)
                                hiHead = e;
                            else
                                hiTail.next = e;
                            hiTail = e;
                        }
                    } while ((e = next) != null);
                    if (loTail != null) {
                        loTail.next = null;
                        newTab[j] = loHead;
                    }
                    if (hiTail != null) {
                        hiTail.next = null;
                        newTab[j + oldCap] = hiHead;
                    }
                }
            }
        }
    }
    //返回扩容后的hashMap
    return newTab;
}
```

- put

```java
public V put(K key, V value) {
    /**四个参数，第一个hash值，第四个参数表示如果该key存在值，如果为null的话，则插入新的value，最后一个参数，在hashMap中没有用，可以不用管，使用默认的即可**/
    return putVal(hash(key), key, value, false, true);
}
 
final V putVal(int hash, K key, V value, boolean onlyIfAbsent,
               boolean evict) {
    //tab 哈希数组，p 该哈希桶的首节点，n hashMap的长度，i 计算出的数组下标
    Node<K,V>[] tab; Node<K,V> p; int n, i;
    //获取长度并进行扩容，使用的是懒加载，table一开始是没有加载的，等put后才开始加载
    if ((tab = table) == null || (n = tab.length) == 0)
        n = (tab = resize()).length;
    /**如果计算出的该哈希桶的位置没有值，则把新插入的key-value放到此处，此处就算没有插入成功，也就是发生哈希冲突时也会把哈希桶的首节点赋予p**/
    if ((p = tab[i = (n - 1) & hash]) == null)
        tab[i] = newNode(hash, key, value, null);
    //发生哈希冲突的几种情况
    else {
        // e 临时节点的作用， k 存放该当前节点的key 
        Node<K,V> e; K k;
        //第一种，插入的key-value的hash值，key都与当前节点的相等，e = p，则表示为首节点
        if (p.hash == hash &&
            ((k = p.key) == key || (key != null && key.equals(k))))
            e = p;
        //第二种，hash值不等于首节点，判断该p是否属于红黑树的节点
        else if (p instanceof TreeNode)
            /**为红黑树的节点，则在红黑树中进行添加，如果该节点已经存在，则返回该节点（不为null），该值很重要，用来判断put操作是否成功，如果添加成功返回null**/
            e = ((TreeNode<K,V>)p).putTreeVal(this, tab, hash, key, value);
        //第三种，hash值不等于首节点，不为红黑树的节点，则为链表的节点
        else {
            //遍历该链表
            for (int binCount = 0; ; ++binCount) {
                //如果找到尾部，则表明添加的key-value没有重复，在尾部进行添加
                if ((e = p.next) == null) {
                    p.next = newNode(hash, key, value, null);
                    //判断是否要转换为红黑树结构
                    if (binCount >= TREEIFY_THRESHOLD - 1) 
                        treeifyBin(tab, hash);
                    break;
                }
                //如果链表中有重复的key，e则为当前重复的节点，结束循环
                if (e.hash == hash &&
                    ((k = e.key) == key || (key != null && key.equals(k))))
                    break;
                p = e;
            }
        }
        //有重复的key，则用待插入值进行覆盖，返回旧值。
        if (e != null) { 
            V oldValue = e.value;
            if (!onlyIfAbsent || oldValue == null)
                e.value = value;
            afterNodeAccess(e);
            return oldValue;
        }
    }
    //到了此步骤，则表明待插入的key-value是没有key的重复，因为插入成功e节点的值为null
    //修改次数+1
    ++modCount;
    //实际长度+1，判断是否大于临界值，大于则扩容
    if (++size > threshold)
        resize();
    afterNodeInsertion(evict);
    //添加成功
    return null;
}
```

## remove

- ps：删除还有一个 clear 方法，把所有数组下标元素置为 null。

```java
public V remove(Object key) {
    //临时变量
    Node<K,V> e;
    /**调用removeNode(hash(key), key, null, false, true)进行删除，第三个value为null，表示，把key的节点直接都删除了，不需要用到值，如果设为值，则还需要去进行查找操作**/
    return (e = removeNode(hash(key), key, null, false, true)) == null ?
        null : e.value;
}

/**第一参数为哈希值，第二个为key，第三个value，第四个为是为true的话，则表示删除它key对应的value，不删除key,第四个如果为false，则表示删除后，不移动节点**/
final Node<K,V> removeNode(int hash, Object key, Object value,
                           boolean matchValue, boolean movable) {
    //tab 哈希数组，p 数组下标的节点，n 长度，index 当前数组下标
    Node<K,V>[] tab; Node<K,V> p; int n, index;
    //哈希数组不为null，且长度大于0，然后获得到要删除key的节点所在是数组下标位置
    if ((tab = table) != null && (n = tab.length) > 0 &&
        (p = tab[index = (n - 1) & hash]) != null) {
        //nodee 存储要删除的节点，e 临时变量，k 当前节点的key，v 当前节点的value
        Node<K,V> node = null, e; K k; V v;
        //如果数组下标的节点正好是要删除的节点，把值赋给临时变量node
        if (p.hash == hash &&
            ((k = p.key) == key || (key != null && key.equals(k))))
            node = p;
        //也就是要删除的节点，在链表或者红黑树上，先判断是否为红黑树的节点
        else if ((e = p.next) != null) {
            if (p instanceof TreeNode)
                //遍历红黑树，找到该节点并返回
                node = ((TreeNode<K,V>)p).getTreeNode(hash, key);
            else { //表示为链表节点，一样的遍历找到该节点
                do {
                    if (e.hash == hash &&
                        ((k = e.key) == key ||
                         (key != null && key.equals(k)))) {
                        node = e;
                        break;
                    }
                    /**注意，如果进入了链表中的遍历，那么此处的p不再是数组下标的节点，而是要删除结点的上一个结点**/
                    p = e;
                } while ((e = e.next) != null);
            }
        }
        //找到要删除的节点后，判断!matchValue，我们正常的remove删除，!matchValue都为true
        if (node != null && (!matchValue || (v = node.value) == value ||
                             (value != null && value.equals(v)))) {
            //如果删除的节点是红黑树结构，则去红黑树中删除
            if (node instanceof TreeNode)
                ((TreeNode<K,V>)node).removeTreeNode(this, tab, movable);
            //如果是链表结构，且删除的节点为数组下标节点，也就是头结点，直接让下一个作为头
            else if (node == p)
                tab[index] = node.next;
            else /**为链表结构，删除的节点在链表中，把要删除的下一个结点设为上一个结点的下一个节点**/
                p.next = node.next;
            //修改计数器
            ++modCount;
            //长度减一
            --size;
            /**此方法在hashMap中是为了让子类去实现，主要是对删除结点后的链表关系进行处理**/
            afterNodeRemoval(node);
            //返回删除的节点
            return node;
        }
    }
    //返回null则表示没有该节点，删除失败
    return null;
}	
```

## get

```java
public V get(Object key) {
    Node<K,V> e;
    //也是调用getNode方法来完成的
    return (e = getNode(hash(key), key)) == null ? null : e.value;
}
 
final Node<K,V> getNode(int hash, Object key) {
    //first 头结点，e 临时变量，n 长度,k key
    Node<K,V>[] tab; Node<K,V> first, e; int n; K k;
    //头结点也就是数组下标的节点
    if ((tab = table) != null && (n = tab.length) > 0 &&
        (first = tab[(n - 1) & hash]) != null) {
        //如果是头结点，则直接返回头结点
        if (first.hash == hash && 
            ((k = first.key) == key || (key != null && key.equals(k))))
            return first;
        //不是头结点
        if ((e = first.next) != null) {
            //判断是否是红黑树结构
            if (first instanceof TreeNode)
                //去红黑树中找，然后返回
                return ((TreeNode<K,V>)first).getTreeNode(hash, key);
            do { //链表节点，一样遍历链表，找到该节点并返回
                if (e.hash == hash &&
                    ((k = e.key) == key || (key != null && key.equals(k))))
                    return e;
            } while ((e = e.next) != null);
        }
    }
    //找不到，表示不存在该节点
    return null;
}
```

## treeify

```java
final void treeifyBin(Node<K,V>[] tab, int hash) {
    int n, index; Node<K,V> e;
    /**
	 * 值得一提的是，并不是 Bucket 里有八个元素就会转化成红黑树，必须得满足散列表容量大于64。
 	*/
    if (tab == null || (n = tab.length) < MIN_TREEIFY_CAPACITY)
        resize();
    else if ((e = tab[index = (n - 1) & hash]) != null) {
        TreeNode<K,V> hd = null, tl = null;
        do {
            TreeNode<K,V> p = replacementTreeNode(e, null);
            if (tl == null)
                hd = p;
            else {
                p.prev = tl;
                tl.next = p;
            }
            tl = p;
        } while ((e = e.next) != null);
        if ((tab[index] = hd) != null)
            hd.treeify(tab);
    }
}
```

## 总结

- 关于实现

JDK 1.8 采用的是 数组+链表+红黑树 来实现 HashMap。

- 关于寻址

在调用 HashMap 的 put 或者 get 时，都会先调用 hashCode() ，得到对应的哈希值，然后与（容量-1）进行按位与，即 e.hash & (length - 1)，得到 bucket 的下标。

- 关于 get

寻址后，返回对象值。

- 关于 put

这里会有一个 哈希冲突 以及 扩容的问题。

1. 哈希冲突

HashMap 采用的是拉链法来解决哈希冲突，与 JDK1.7 不同的是，JDK1.8 采用了尾插法，能够避免出现逆序且链表循环的问题。

2. 扩容 resize（）

- 关于扩容机制

其实说到底就是把 bucket 长度扩容到两倍，然后把所有节点 rehash。

>  e.hash & （newCap - 1） -> e.hash & (oldCap * 2 - 1)

这里有个结论就是新旧两次计算下标的结果，要么相同，要么就是旧下标 + 原数组长度，也就是取决于 oldCap 二进制右移多出来的那一位。

- 关于链表与红黑树转化的阈值

值得一提的是，**并不是 Bucket 里有八个元素就会转化成红黑树，必须得满足散列表容量大于64**。

> [容器中节点分布在hash桶中的频率遵循泊松分布](http://en.wikipedia.org/wiki/Poisson_distribution)

源码里表面了理想情况应该使用随机的哈希码，

但是，按照泊松分布的计算公式计算出了桶中元素个数和概率的对照表，可以看到链表中元素个数为8时的概率已经非常小，再多的就更少了，所以原作者在选择链表元素个数时选择了8，是根据概率统计而选择的。

- 关于重载因子

选择0.75是提高空间利用率和减少查询成本的折中，主要原因还是泊松分布，0.75的碰撞最小。

反证：

1. 加载因子为1，表示 resize（）的阈值变大，这意味着空间利用率的提高，但是同时也增加了查询的成本。
2. 加载因子为1，表示 resize（）阈值变小，空间利用率低，rehash操作过多。

- 关于容量为2的幂

这里应该提一下 hash 的 概念，也就是散列。

把一大堆数，映射到 N 个桶里，举个例子就是把 1~100000 分别放到 N个桶里。

正常思维是做取余运算，但是效率太低了。

换位思考，利用计算机的基础运算，位运算来做，就是把数字转换成二进制。

所以 HashMap 的 哈希运算是 ：  e.hash & (length - 1)

把容量设置成 2 的幂，这样可以使元素的分布更加均匀。

当然 在 resize 里也有相关的二进制操作。
